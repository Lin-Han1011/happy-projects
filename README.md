# Lin Han's Individual Python Projects
The repository contains my personal predictive modeling and data cleaning and data visualization projects. 

1. The 'Bank client churn project' aims to forecast/classify if a client will leave the bank or not for an European bank. 
The dataset I used in my project is downloaded from Kaggle website: https://www.kaggle.com/adammaus/predicting-churn-for-bank-customers. It contains 10,000 observations and 14 variables, including 13 independent variables and 1 binary dependent variable 'Exited' that records if a bank client churn or not churn. 
I firstly explored the dataset and visualized variables and correlations to check if the assumptions of logistic regression model are met. Then, I used variables to build a logistic regression model and the final accuracy is 81.5%. I also developed two random forest non-parameter models using different variables (the higher testing accuracy is 86.85%) to compare with the logistic regression model, and further improvement will be made for both models. 

2. The 'Data preprocessing capital budget Toronto project' aims to clean the dirty data, and then build a Tableau dashboard (link: https://public.tableau.com/profile/lin.han8837#!/) using Toronto open source data set "Budget - Capital Budget & Plan By Ward (10 Year Recommended)".The data set source is https://www.toronto.ca/city-government/data-research-maps/open-data/open-data-catalogue/finance/#463113ed-6ad1-c05f-9ed5-f8965f40f7d3. 
The topic is "Future 5 years opportunities of city construction projects in Toronto". The potential audiences are "Representatives of Construction firms". My dashboard can provide insights of what is the 10-year (from 2015 to 2024) trend of governmentsâ€™ investment on Toronto Construction projects, especially the budget allocation for next 5 years. Therefore, they can do preparations in advance and increase their competitive advantages such as buying equipment or hiring employees.

3. The 'MySQL Database Information Extraction Project' aims to extract and process tables stored in MySQL using SQLAlchemy and Pandas packages. 
I firstly imported packages and connected to a MySQL relational database named "sql_invocing" which stored 4 tables: 'clients', 'invoices', 'payment_methods', 'payments'. Then, I checked tables' details in the database and printed all table's primary key column and other columns. Thirdly, I created Pandas dataframes from MySQL tables and set index to the corresponding primary key. Lastly, I built analytical SQL queries to (1)extract subsets of information, (2)update clients' payment information, (3)create new clients' records, (4)delete useless record.
